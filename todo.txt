In no particular order:

- debug why no checkpoint is saved apart from last.ckpt even when save_top_k > 1
- create a method to obtain statistics about the latent space of an autoencoder
    - encode a few batched and cache them (maybe in a independent method)
    - use them to compute things like medians, means, quantiles, stddevs, etc. Generate histograms, plots, etc.
- implement more sophisticated embedding perturbations
    - use classifier to guide exploration. e.g. use gradients of logits and do GD in input space, or 
      define an energy and do MCMC
- implement other autoencoder variants (e.g. VAE, VQVAE)
- setup 'generative data augmentation' at the input layer
- generalize to any hidden layer

- to understand hidden layer perturbations (of any kind, including through a perturbation in the latent space on an AE),
  setup the following: given a dataset and a classifier, collect all hidden representations at that level of the datapoints.
  then, do nearest neighbor queries to interpret the 'moves' in hidden representation space.