Next Steps:

- reproduce results with gda on input layer
- experiment with hidden layers


More:

- when optimizing proba constrained on the AE manifold, inject noise in classifier?
  - similar to SGD noise in analogy with weight landscape (face a noisy sample from data distro at every iteration,
    here e.g. face a classifier from a ball around a reference one)
  - flatness/sharpness?
    - adversarial vs genuine examples
    - optimizing (adversarial) with/without noise as described above
  - mode connectivity in input space?
    - adversarial examples different from genuine?
- can improve:
    - statistics about latent space
    - sampling around an embedding in latent space exploration (more options, e.g. sample at multiple
      gaussian noise levels or do a MCMC guided by probas)
- implement other autoencoder variants (e.g. VAE, VQVAE)
- to understand hidden layer perturbations (of any kind, including through a perturbation in the latent space on an AE),
  setup the following: given a dataset and a classifier, collect all hidden representations at that level of the datapoints.
  then, do nearest neighbor queries to interpret the 'moves' in hidden representation space.